{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/home/tousside/Documents/recrutement/cowrywise-customer-plan-abandonment/research'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir(\"../\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"artifacts/data_transformation/train.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 2113 entries, 0 to 2112\n",
      "Data columns (total 9 columns):\n",
      " #   Column                    Non-Null Count  Dtype  \n",
      "---  ------                    --------------  -----  \n",
      " 0   gender_id                 1756 non-null   float64\n",
      " 1   risk_apetite              2113 non-null   int64  \n",
      " 2   fraud_score               2113 non-null   int64  \n",
      " 3   monthly_expense           2113 non-null   float64\n",
      " 4   type                      2113 non-null   object \n",
      " 5   total_transactions        2113 non-null   int64  \n",
      " 6   total_transaction_amount  2113 non-null   float64\n",
      " 7   total_withdrawn_amount    2113 non-null   float64\n",
      " 8   plan_abondonment          2113 non-null   int64  \n",
      "dtypes: float64(4), int64(4), object(1)\n",
      "memory usage: 148.7+ KB\n"
     ]
    }
   ],
   "source": [
    "data.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# set categorical variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# gender_id , and type as categorical variables\n",
    "categorical_cols = [\"gender_id\", \"type\"]\n",
    "data[categorical_cols] = data[categorical_cols].astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 2113 entries, 0 to 2112\n",
      "Data columns (total 9 columns):\n",
      " #   Column                    Non-Null Count  Dtype  \n",
      "---  ------                    --------------  -----  \n",
      " 0   gender_id                 2113 non-null   object \n",
      " 1   risk_apetite              2113 non-null   int64  \n",
      " 2   fraud_score               2113 non-null   int64  \n",
      " 3   monthly_expense           2113 non-null   float64\n",
      " 4   type                      2113 non-null   object \n",
      " 5   total_transactions        2113 non-null   int64  \n",
      " 6   total_transaction_amount  2113 non-null   float64\n",
      " 7   total_withdrawn_amount    2113 non-null   float64\n",
      " 8   plan_abondonment          2113 non-null   int64  \n",
      "dtypes: float64(3), int64(4), object(2)\n",
      "memory usage: 148.7+ KB\n"
     ]
    }
   ],
   "source": [
    "data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1: Separate features and target\n",
    "X = data.drop(columns=\"plan_abondonment\")\n",
    "y = data[\"plan_abondonment\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TReat non values for gender_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.ensemble import RandomForestClassifier  # or any other model\n",
    "from sklearn.feature_extraction import DictVectorizer\n",
    "from sklearn.preprocessing import StandardScaler, FunctionTransformer\n",
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "categorical_cols = [\"gender_id\", \"type\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# get numerical variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = data.drop(columns=\"plan_abondonment\")\n",
    "y_train = data[\"plan_abondonment\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "numeric_cols = X_train.select_dtypes(include=[\"int64\", \"float64\"]).columns.tolist()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 3: ColumnTransformer for imputing\n",
    "preprocessor = ColumnTransformer(transformers=[\n",
    "    (\"num\", SimpleImputer(strategy=\"median\"), numeric_cols),\n",
    "    (\"scaler\", StandardScaler(), numeric_cols),\n",
    "    (\"cat\", SimpleImputer(strategy=\"most_frequent\"), categorical_cols)\n",
    "], remainder=\"passthrough\")  # Keep other columns (if any)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 4: Function to rebuild DataFrame from transformed array\n",
    "def to_dataframe(X_array):\n",
    "    return pd.DataFrame(X_array, columns=numeric_cols + categorical_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def array_to_str_keyed_dict_list(X):\n",
    "    \"\"\"\n",
    "    Converts a 2D array into a list of dictionaries\n",
    "    where keys are string representations of column indices.\n",
    "    \"\"\"\n",
    "    return [dict(zip(map(str, range(X.shape[1])), row)) for row in X]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Full pipeline\n",
    "pipeline = Pipeline([\n",
    "    (\"preprocessing\", preprocessor),\n",
    "    (\"to_dict\", FunctionTransformer(array_to_str_keyed_dict_list)),\n",
    "    (\"vectorize\", DictVectorizer()),\n",
    "    (\"clf\", LogisticRegression(max_iter=1000))\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline.fit(X_train, y_train)\n",
    "\n",
    "# Predict\n",
    "y_pred = pipeline.predict(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy: 0.5801418439716312\n"
     ]
    }
   ],
   "source": [
    "test_data = pd.read_csv(\"artifacts/data_transformation/test.csv\")\n",
    "test_data[categorical_cols] = test_data[categorical_cols].astype(str)\n",
    "# Predict on test data\n",
    "test_X = test_data.drop(columns=\"plan_abondonment\")\n",
    "test_y = test_data[\"plan_abondonment\"]\n",
    "y_pred_test = pipeline.predict(test_X)\n",
    "# Evaluate on test data\n",
    "test_acc = accuracy_score(test_y, y_pred_test)\n",
    "print(\"Test Accuracy:\", test_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>gender_id</th>\n",
       "      <th>risk_apetite</th>\n",
       "      <th>fraud_score</th>\n",
       "      <th>monthly_expense</th>\n",
       "      <th>type</th>\n",
       "      <th>total_transactions</th>\n",
       "      <th>total_transaction_amount</th>\n",
       "      <th>total_withdrawn_amount</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>nan</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Investment</td>\n",
       "      <td>1</td>\n",
       "      <td>5000000.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>40000000.0</td>\n",
       "      <td>Savings</td>\n",
       "      <td>319</td>\n",
       "      <td>111000000.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>100000000.0</td>\n",
       "      <td>Investment</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2.0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>5000000.0</td>\n",
       "      <td>Savings</td>\n",
       "      <td>27</td>\n",
       "      <td>2000000.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>nan</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>100000000.0</td>\n",
       "      <td>Savings</td>\n",
       "      <td>5</td>\n",
       "      <td>10000000.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  gender_id  risk_apetite  fraud_score  monthly_expense        type  \\\n",
       "0       nan             0            0              0.0  Investment   \n",
       "1       2.0             1            0       40000000.0     Savings   \n",
       "2       1.0             2            0      100000000.0  Investment   \n",
       "3       2.0             2            0        5000000.0     Savings   \n",
       "4       nan             0            0      100000000.0     Savings   \n",
       "\n",
       "   total_transactions  total_transaction_amount  total_withdrawn_amount  \n",
       "0                   1                 5000000.0                     0.0  \n",
       "1                 319               111000000.0                     0.0  \n",
       "2                   1                       0.0                     0.0  \n",
       "3                  27                 2000000.0                     0.0  \n",
       "4                   5                10000000.0                     0.0  "
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['gender_id', 'risk_apetite', 'fraud_score', 'monthly_expense', 'type',\n",
       "       'total_transactions', 'total_transaction_amount',\n",
       "       'total_withdrawn_amount'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0, 15, 10, 20, 50])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train[\"fraud_score\"].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Random forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Full pipeline\n",
    "pipeline = Pipeline([\n",
    "    (\"preprocessing\", preprocessor),\n",
    "    (\"to_dict\", FunctionTransformer(array_to_str_keyed_dict_list)),\n",
    "    (\"vectorize\", DictVectorizer()),\n",
    "    (\"clf\", RandomForestClassifier(random_state=42))\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline.fit(X_train, y_train)\n",
    "\n",
    "# Predict\n",
    "y_pred = pipeline.predict(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.972077614765736\n"
     ]
    }
   ],
   "source": [
    "acc = accuracy_score(y_train, y_pred)\n",
    "print(\"Accuracy:\", acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy: 0.8312056737588652\n"
     ]
    }
   ],
   "source": [
    "test_data = pd.read_csv(\"artifacts/data_transformation/test.csv\")\n",
    "test_data[categorical_cols] = test_data[categorical_cols].astype(str)\n",
    "# Predict on test data\n",
    "test_X = test_data.drop(columns=\"plan_abondonment\")\n",
    "test_y = test_data[\"plan_abondonment\"]\n",
    "y_pred_test = pipeline.predict(test_X)\n",
    "# Evaluate on test data\n",
    "test_acc = accuracy_score(test_y, y_pred_test)\n",
    "print(\"Test Accuracy:\", test_acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# xgboost classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "from xgboost import XGBClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Full pipeline\n",
    "pipeline = Pipeline([\n",
    "    (\"preprocessing\", preprocessor),\n",
    "    (\"to_dict\", FunctionTransformer(array_to_str_keyed_dict_list)),\n",
    "    (\"vectorize\", DictVectorizer()),\n",
    "     ('classifier', XGBClassifier())\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline.fit(X_train, y_train)\n",
    "\n",
    "# Predict\n",
    "y_pred = pipeline.predict(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9526739233317558\n"
     ]
    }
   ],
   "source": [
    "acc = accuracy_score(y_train, y_pred)\n",
    "print(\"Accuracy:\", acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy: 0.8411347517730496\n"
     ]
    }
   ],
   "source": [
    "test_data = pd.read_csv(\"artifacts/data_transformation/test.csv\")\n",
    "test_data[categorical_cols] = test_data[categorical_cols].astype(str)\n",
    "# Predict on test data\n",
    "test_X = test_data.drop(columns=\"plan_abondonment\")\n",
    "test_y = test_data[\"plan_abondonment\"]\n",
    "y_pred_test = pipeline.predict(test_X)\n",
    "# Evaluate on test data\n",
    "test_acc = accuracy_score(test_y, y_pred_test)\n",
    "print(\"Test Accuracy:\", test_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import (\n",
    "    accuracy_score, precision_score, recall_score, f1_score,\n",
    "    roc_auc_score, log_loss, confusion_matrix, classification_report,\n",
    "    average_precision_score, cohen_kappa_score\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data = pd.read_csv(\"artifacts/data_transformation/test.csv\")\n",
    "test_data[categorical_cols] = test_data[categorical_cols].astype(str)\n",
    "# Predict on test data\n",
    "test_X = test_data.drop(columns=\"plan_abondonment\")\n",
    "test_y = test_data[\"plan_abondonment\"]\n",
    "y_pred_test = pipeline.predict(test_X)\n",
    "# Evaluate on test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.79      0.83      0.81       289\n",
      "           1       0.88      0.85      0.86       416\n",
      "\n",
      "    accuracy                           0.84       705\n",
      "   macro avg       0.84      0.84      0.84       705\n",
      "weighted avg       0.84      0.84      0.84       705\n",
      "\n",
      "ROC AUC: 0.913794250731967\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report, roc_auc_score\n",
    "\n",
    "print(classification_report(test_y, y_pred_test))\n",
    "y_proba = pipeline.predict_proba(test_X)[:, 1]  # Get probabilities for the positive class\n",
    "print(\"ROC AUC:\", roc_auc_score(test_y, y_proba))  # use y_proba for probabilistic output\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# modular codes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataclasses import dataclass\n",
    "from pathlib import Path\n",
    "\n",
    "@dataclass(frozen=True)\n",
    "class ModelTrainerConfig:\n",
    "    root_dir: Path\n",
    "    train_data_path: Path\n",
    "    test_data_path: Path\n",
    "    model_name: str\n",
    "    model_params: dict\n",
    "    target_column: str"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mlProject.constants import *\n",
    "from mlProject.utils.common import read_yaml, create_directories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConfigurationManager:\n",
    "    def __init__(\n",
    "        self,\n",
    "        config_filepath = CONFIG_FILE_PATH,\n",
    "        params_filepath = PARAMS_FILE_PATH,\n",
    "        schema_filepath = SCHEMA_FILE_PATH):\n",
    "\n",
    "        self.config = read_yaml(config_filepath)\n",
    "        self.params = read_yaml(params_filepath)\n",
    "        self.schema = read_yaml(schema_filepath)\n",
    "\n",
    "        create_directories([self.config.artifacts_root])\n",
    "\n",
    "\n",
    "    def get_model_trainer_config(self) -> ModelTrainerConfig:\n",
    "        config = self.config.model_trainer\n",
    "        model_params = self.params.XGBoost\n",
    "        schema =  self.schema.TARGET_COLUMN\n",
    "\n",
    "        create_directories([config.root_dir])\n",
    "\n",
    "        model_trainer_config = ModelTrainerConfig(\n",
    "            root_dir=config.root_dir,\n",
    "            train_data_path = config.train_data_path,\n",
    "            test_data_path = config.test_data_path,\n",
    "            model_name = config.model_name,\n",
    "            model_params = model_params,\n",
    "            target_column = schema.name\n",
    "            \n",
    "        )\n",
    "\n",
    "        return model_trainer_config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.ensemble import RandomForestClassifier  # or any other model\n",
    "from sklearn.feature_extraction import DictVectorizer\n",
    "from sklearn.preprocessing import StandardScaler, FunctionTransformer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "import joblib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ModelTrainer:\n",
    "    def __init__(self, config: ModelTrainerConfig):\n",
    "        self.config = config\n",
    "    def array_to_str_keyed_dict_list(self, X):\n",
    "        \"\"\"\n",
    "        Converts a 2D array into a list of dictionaries\n",
    "        where keys are string representations of column indices.\n",
    "        \"\"\"\n",
    "        return [dict(zip(map(str, range(X.shape[1])), row)) for row in X]\n",
    "\n",
    "    \n",
    "    def train(self):\n",
    "        train_data = pd.read_csv(self.config.train_data_path)\n",
    "        test_data = pd.read_csv(self.config.test_data_path)\n",
    "\n",
    "\n",
    "        train_x = train_data.drop([self.config.target_column], axis=1)\n",
    "        test_x = test_data.drop([self.config.target_column], axis=1)\n",
    "        train_y = train_data[[self.config.target_column]]\n",
    "        test_y = test_data[[self.config.target_column]]\n",
    "        \n",
    "        # gender_id , and type as categorical variables\n",
    "        categorical_cols = [\"gender_id\", \"type\"]\n",
    "        train_x[categorical_cols] = train_x[categorical_cols].astype(str)\n",
    "        \n",
    "        numeric_cols = train_x.select_dtypes(include=[\"int64\", \"float64\"]).columns.tolist()\n",
    "        \n",
    "        # Step 3: ColumnTransformer for imputing\n",
    "        preprocessor = ColumnTransformer(transformers=[\n",
    "            (\"num\", SimpleImputer(strategy=\"median\"), numeric_cols),\n",
    "            (\"scaler\", StandardScaler(), numeric_cols),\n",
    "            (\"cat\", SimpleImputer(strategy=\"most_frequent\"), categorical_cols)\n",
    "        ], remainder=\"passthrough\")  # Keep other columns (if any)\n",
    "\n",
    "        pipeline = Pipeline([\n",
    "            (\"preprocessing\", preprocessor),\n",
    "            (\"to_dict\", FunctionTransformer(self.array_to_str_keyed_dict_list)),\n",
    "            (\"vectorize\", DictVectorizer()),\n",
    "            ('classifier', XGBClassifier(**self.config.model_params, random_state=42))\n",
    "        ])\n",
    "\n",
    "        \n",
    "        pipeline.fit(train_x, train_y)\n",
    "\n",
    "        joblib.dump(pipeline, os.path.join(self.config.root_dir, self.config.model_name))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025-05-29 11:44:25,611: INFO: common: yaml file: config/config.yaml loaded successfully]\n",
      "[2025-05-29 11:44:25,612: INFO: common: yaml file: params.yaml loaded successfully]\n",
      "[2025-05-29 11:44:25,614: INFO: common: yaml file: schema.yaml loaded successfully]\n",
      "[2025-05-29 11:44:25,615: INFO: common: created directory at: artifacts]\n",
      "[2025-05-29 11:44:25,615: INFO: common: created directory at: artifacts/model_trainer]\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    config = ConfigurationManager()\n",
    "    model_trainer_config = config.get_model_trainer_config()\n",
    "    model_trainer_config = ModelTrainer(config=model_trainer_config)\n",
    "    model_trainer_config.train()\n",
    "except Exception as e:\n",
    "    raise e"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
