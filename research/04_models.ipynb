{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/home/tousside/Documents/recrutement/cowrywise-customer-plan-abandonment/research'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir(\"../\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"artifacts/data_transformation/train.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 2113 entries, 0 to 2112\n",
      "Data columns (total 9 columns):\n",
      " #   Column                    Non-Null Count  Dtype  \n",
      "---  ------                    --------------  -----  \n",
      " 0   gender_id                 1756 non-null   float64\n",
      " 1   risk_apetite              2113 non-null   int64  \n",
      " 2   fraud_score               2113 non-null   int64  \n",
      " 3   monthly_expense           2113 non-null   float64\n",
      " 4   type                      2113 non-null   object \n",
      " 5   total_transactions        2113 non-null   int64  \n",
      " 6   total_transaction_amount  2113 non-null   float64\n",
      " 7   total_withdrawn_amount    2113 non-null   float64\n",
      " 8   plan_abondonment          2113 non-null   int64  \n",
      "dtypes: float64(4), int64(4), object(1)\n",
      "memory usage: 148.7+ KB\n"
     ]
    }
   ],
   "source": [
    "data.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# set categorical variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# gender_id , and type as categorical variables\n",
    "categorical_cols = [\"gender_id\", \"type\"]\n",
    "data[categorical_cols] = data[categorical_cols].astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 2113 entries, 0 to 2112\n",
      "Data columns (total 9 columns):\n",
      " #   Column                    Non-Null Count  Dtype  \n",
      "---  ------                    --------------  -----  \n",
      " 0   gender_id                 2113 non-null   object \n",
      " 1   risk_apetite              2113 non-null   int64  \n",
      " 2   fraud_score               2113 non-null   int64  \n",
      " 3   monthly_expense           2113 non-null   float64\n",
      " 4   type                      2113 non-null   object \n",
      " 5   total_transactions        2113 non-null   int64  \n",
      " 6   total_transaction_amount  2113 non-null   float64\n",
      " 7   total_withdrawn_amount    2113 non-null   float64\n",
      " 8   plan_abondonment          2113 non-null   int64  \n",
      "dtypes: float64(3), int64(4), object(2)\n",
      "memory usage: 148.7+ KB\n"
     ]
    }
   ],
   "source": [
    "data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1: Separate features and target\n",
    "X = data.drop(columns=\"plan_abondonment\")\n",
    "y = data[\"plan_abondonment\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TReat non values for gender_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.ensemble import RandomForestClassifier  # or any other model\n",
    "from sklearn.feature_extraction import DictVectorizer\n",
    "from sklearn.preprocessing import StandardScaler, FunctionTransformer\n",
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "categorical_cols = [\"gender_id\", \"type\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# get numerical variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = data.drop(columns=\"plan_abondonment\")\n",
    "y_train = data[\"plan_abondonment\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "numeric_cols = X_train.select_dtypes(include=[\"int64\", \"float64\"]).columns.tolist()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 3: ColumnTransformer for imputing\n",
    "preprocessor = ColumnTransformer(transformers=[\n",
    "    (\"num\", SimpleImputer(strategy=\"median\"), numeric_cols),\n",
    "    (\"scaler\", StandardScaler(), numeric_cols),\n",
    "    (\"cat\", SimpleImputer(strategy=\"most_frequent\"), categorical_cols)\n",
    "], remainder=\"passthrough\")  # Keep other columns (if any)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 4: Function to rebuild DataFrame from transformed array\n",
    "def to_dataframe(X_array):\n",
    "    return pd.DataFrame(X_array, columns=numeric_cols + categorical_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def array_to_str_keyed_dict_list(X):\n",
    "    \"\"\"\n",
    "    Converts a 2D array into a list of dictionaries\n",
    "    where keys are string representations of column indices.\n",
    "    \"\"\"\n",
    "    return [dict(zip(map(str, range(X.shape[1])), row)) for row in X]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Full pipeline\n",
    "pipeline = Pipeline([\n",
    "    (\"preprocessing\", preprocessor),\n",
    "    (\"to_dict\", FunctionTransformer(array_to_str_keyed_dict_list)),\n",
    "    (\"vectorize\", DictVectorizer()),\n",
    "    (\"clf\", LogisticRegression(max_iter=1000))\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline.fit(X_train, y_train)\n",
    "\n",
    "# Predict\n",
    "y_pred = pipeline.predict(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy: 0.5801418439716312\n"
     ]
    }
   ],
   "source": [
    "test_data = pd.read_csv(\"artifacts/data_transformation/test.csv\")\n",
    "test_data[categorical_cols] = test_data[categorical_cols].astype(str)\n",
    "# Predict on test data\n",
    "test_X = test_data.drop(columns=\"plan_abondonment\")\n",
    "test_y = test_data[\"plan_abondonment\"]\n",
    "y_pred_test = pipeline.predict(test_X)\n",
    "# Evaluate on test data\n",
    "test_acc = accuracy_score(test_y, y_pred_test)\n",
    "print(\"Test Accuracy:\", test_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Random forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Full pipeline\n",
    "pipeline = Pipeline([\n",
    "    (\"preprocessing\", preprocessor),\n",
    "    (\"to_dict\", FunctionTransformer(array_to_str_keyed_dict_list)),\n",
    "    (\"vectorize\", DictVectorizer()),\n",
    "    (\"clf\", RandomForestClassifier(random_state=42))\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline.fit(X_train, y_train)\n",
    "\n",
    "# Predict\n",
    "y_pred = pipeline.predict(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.972077614765736\n"
     ]
    }
   ],
   "source": [
    "acc = accuracy_score(y_train, y_pred)\n",
    "print(\"Accuracy:\", acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy: 0.8312056737588652\n"
     ]
    }
   ],
   "source": [
    "test_data = pd.read_csv(\"artifacts/data_transformation/test.csv\")\n",
    "test_data[categorical_cols] = test_data[categorical_cols].astype(str)\n",
    "# Predict on test data\n",
    "test_X = test_data.drop(columns=\"plan_abondonment\")\n",
    "test_y = test_data[\"plan_abondonment\"]\n",
    "y_pred_test = pipeline.predict(test_X)\n",
    "# Evaluate on test data\n",
    "test_acc = accuracy_score(test_y, y_pred_test)\n",
    "print(\"Test Accuracy:\", test_acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# xgboost classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "from xgboost import XGBClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Full pipeline\n",
    "pipeline = Pipeline([\n",
    "    (\"preprocessing\", preprocessor),\n",
    "    (\"to_dict\", FunctionTransformer(array_to_str_keyed_dict_list)),\n",
    "    (\"vectorize\", DictVectorizer()),\n",
    "     ('classifier', XGBClassifier())\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline.fit(X_train, y_train)\n",
    "\n",
    "# Predict\n",
    "y_pred = pipeline.predict(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9526739233317558\n"
     ]
    }
   ],
   "source": [
    "acc = accuracy_score(y_train, y_pred)\n",
    "print(\"Accuracy:\", acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy: 0.8411347517730496\n"
     ]
    }
   ],
   "source": [
    "test_data = pd.read_csv(\"artifacts/data_transformation/test.csv\")\n",
    "test_data[categorical_cols] = test_data[categorical_cols].astype(str)\n",
    "# Predict on test data\n",
    "test_X = test_data.drop(columns=\"plan_abondonment\")\n",
    "test_y = test_data[\"plan_abondonment\"]\n",
    "y_pred_test = pipeline.predict(test_X)\n",
    "# Evaluate on test data\n",
    "test_acc = accuracy_score(test_y, y_pred_test)\n",
    "print(\"Test Accuracy:\", test_acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# modular codes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataclasses import dataclass\n",
    "from pathlib import Path\n",
    "\n",
    "@dataclass(frozen=True)\n",
    "class ModelTrainerConfig:\n",
    "    root_dir: Path\n",
    "    train_data_path: Path\n",
    "    test_data_path: Path\n",
    "    model_name: str\n",
    "    model_params: dict\n",
    "    target_column: str"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mlProject.constants import *\n",
    "from mlProject.utils.common import read_yaml, create_directories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConfigurationManager:\n",
    "    def __init__(\n",
    "        self,\n",
    "        config_filepath = CONFIG_FILE_PATH,\n",
    "        params_filepath = PARAMS_FILE_PATH,\n",
    "        schema_filepath = SCHEMA_FILE_PATH):\n",
    "\n",
    "        self.config = read_yaml(config_filepath)\n",
    "        self.params = read_yaml(params_filepath)\n",
    "        self.schema = read_yaml(schema_filepath)\n",
    "\n",
    "        create_directories([self.config.artifacts_root])\n",
    "\n",
    "\n",
    "    def get_model_trainer_config(self) -> ModelTrainerConfig:\n",
    "        config = self.config.model_trainer\n",
    "        model_params = self.params.XGBoost\n",
    "        schema =  self.schema.TARGET_COLUMN\n",
    "\n",
    "        create_directories([config.root_dir])\n",
    "\n",
    "        model_trainer_config = ModelTrainerConfig(\n",
    "            root_dir=config.root_dir,\n",
    "            train_data_path = config.train_data_path,\n",
    "            test_data_path = config.test_data_path,\n",
    "            model_name = config.model_name,\n",
    "            model_params = model_params,\n",
    "            target_column = schema.name\n",
    "            \n",
    "        )\n",
    "\n",
    "        return model_trainer_config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.ensemble import RandomForestClassifier  # or any other model\n",
    "from sklearn.feature_extraction import DictVectorizer\n",
    "from sklearn.preprocessing import StandardScaler, FunctionTransformer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "import joblib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ModelTrainer:\n",
    "    def __init__(self, config: ModelTrainerConfig):\n",
    "        self.config = config\n",
    "    def array_to_str_keyed_dict_list(self, X):\n",
    "        \"\"\"\n",
    "        Converts a 2D array into a list of dictionaries\n",
    "        where keys are string representations of column indices.\n",
    "        \"\"\"\n",
    "        return [dict(zip(map(str, range(X.shape[1])), row)) for row in X]\n",
    "\n",
    "    \n",
    "    def train(self):\n",
    "        train_data = pd.read_csv(self.config.train_data_path)\n",
    "        test_data = pd.read_csv(self.config.test_data_path)\n",
    "\n",
    "\n",
    "        train_x = train_data.drop([self.config.target_column], axis=1)\n",
    "        test_x = test_data.drop([self.config.target_column], axis=1)\n",
    "        train_y = train_data[[self.config.target_column]]\n",
    "        test_y = test_data[[self.config.target_column]]\n",
    "        \n",
    "        # gender_id , and type as categorical variables\n",
    "        categorical_cols = [\"gender_id\", \"type\"]\n",
    "        train_x[categorical_cols] = train_x[categorical_cols].astype(str)\n",
    "        \n",
    "        numeric_cols = train_x.select_dtypes(include=[\"int64\", \"float64\"]).columns.tolist()\n",
    "        \n",
    "        # Step 3: ColumnTransformer for imputing\n",
    "        preprocessor = ColumnTransformer(transformers=[\n",
    "            (\"num\", SimpleImputer(strategy=\"median\"), numeric_cols),\n",
    "            (\"scaler\", StandardScaler(), numeric_cols),\n",
    "            (\"cat\", SimpleImputer(strategy=\"most_frequent\"), categorical_cols)\n",
    "        ], remainder=\"passthrough\")  # Keep other columns (if any)\n",
    "\n",
    "        pipeline = Pipeline([\n",
    "            (\"preprocessing\", preprocessor),\n",
    "            (\"to_dict\", FunctionTransformer(self.array_to_str_keyed_dict_list)),\n",
    "            (\"vectorize\", DictVectorizer()),\n",
    "            ('classifier', XGBClassifier(**self.config.model_params, random_state=42))\n",
    "        ])\n",
    "\n",
    "        \n",
    "        pipeline.fit(train_x, train_y)\n",
    "\n",
    "        joblib.dump(pipeline, os.path.join(self.config.root_dir, self.config.model_name))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025-05-29 11:44:25,611: INFO: common: yaml file: config/config.yaml loaded successfully]\n",
      "[2025-05-29 11:44:25,612: INFO: common: yaml file: params.yaml loaded successfully]\n",
      "[2025-05-29 11:44:25,614: INFO: common: yaml file: schema.yaml loaded successfully]\n",
      "[2025-05-29 11:44:25,615: INFO: common: created directory at: artifacts]\n",
      "[2025-05-29 11:44:25,615: INFO: common: created directory at: artifacts/model_trainer]\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    config = ConfigurationManager()\n",
    "    model_trainer_config = config.get_model_trainer_config()\n",
    "    model_trainer_config = ModelTrainer(config=model_trainer_config)\n",
    "    model_trainer_config.train()\n",
    "except Exception as e:\n",
    "    raise e"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
